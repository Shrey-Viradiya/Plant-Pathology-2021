{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Multiclass Classification - PyTorch & NVIDIA DALI","metadata":{}},{"cell_type":"markdown","source":"## Plant Pathology 2021","metadata":{}},{"cell_type":"markdown","source":"### Check GPU Runtime","metadata":{}},{"cell_type":"code","source":"!nvidia-smi","metadata":{"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Fri Apr 16 16:49:47 2021       \n+-----------------------------------------------------------------------------+\n| NVIDIA-SMI 450.51.06    Driver Version: 450.51.06    CUDA Version: 11.0     |\n|-------------------------------+----------------------+----------------------+\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n|                               |                      |               MIG M. |\n|===============================+======================+======================|\n|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n| N/A   66C    P0    33W / 250W |      0MiB / 16280MiB |      0%      Default |\n|                               |                      |                  N/A |\n+-------------------------------+----------------------+----------------------+\n                                                                               \n+-----------------------------------------------------------------------------+\n| Processes:                                                                  |\n|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n|        ID   ID                                                   Usage      |\n|=============================================================================|\n|  No running processes found                                                 |\n+-----------------------------------------------------------------------------+\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Installing NVIDIA-DALI","metadata":{}},{"cell_type":"code","source":"!pip install --extra-index-url https://developer.download.nvidia.com/compute/redist nvidia-dali-cuda110","metadata":{"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Looking in indexes: https://pypi.org/simple, https://developer.download.nvidia.com/compute/redist\nRequirement already satisfied: nvidia-dali-cuda110 in /opt/conda/lib/python3.7/site-packages (1.1.0)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Importing Required Libraries","metadata":{}},{"cell_type":"code","source":"from collections import defaultdict\nimport os\nimport shutil\nimport sys\nimport platform\nimport time\n\nimport numpy as np\nimport pandas as pd\nfrom PIL import Image\nimport matplotlib.pyplot as plt\n\nfrom nvidia.dali import pipeline_def, Pipeline\nimport nvidia.dali.fn as fn\nimport nvidia.dali.types as types\nfrom nvidia.dali.plugin.pytorch import DALIClassificationIterator as PyTorchIterator\nfrom nvidia.dali.plugin.pytorch import LastBatchPolicy\n\nimport torchvision.utils as utils\nimport torch\nimport torchvision\nimport skimage.transform\nfrom skimage import io","metadata":{"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"### Creating OneHot for Training and Testing","metadata":{}},{"cell_type":"code","source":"data = pd.read_csv(\"../input/plant-pathology-2021-fgvc8/train.csv\")\ndata","metadata":{"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"                      image                           labels\n0      800113bb65efe69e.jpg                          healthy\n1      8002cb321f8bfcdf.jpg  scab frog_eye_leaf_spot complex\n2      80070f7fb5e2ccaa.jpg                             scab\n3      80077517781fb94f.jpg                             scab\n4      800cbf0ff87721f8.jpg                          complex\n...                     ...                              ...\n18627  fffb900a92289a33.jpg                          healthy\n18628  fffc488fa4c0e80c.jpg                             scab\n18629  fffc94e092a59086.jpg                             rust\n18630  fffe105cf6808292.jpg          scab frog_eye_leaf_spot\n18631  fffe472a0001bd25.jpg                          healthy\n\n[18632 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>image</th>\n      <th>labels</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>800113bb65efe69e.jpg</td>\n      <td>healthy</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>8002cb321f8bfcdf.jpg</td>\n      <td>scab frog_eye_leaf_spot complex</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>80070f7fb5e2ccaa.jpg</td>\n      <td>scab</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>80077517781fb94f.jpg</td>\n      <td>scab</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>800cbf0ff87721f8.jpg</td>\n      <td>complex</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>18627</th>\n      <td>fffb900a92289a33.jpg</td>\n      <td>healthy</td>\n    </tr>\n    <tr>\n      <th>18628</th>\n      <td>fffc488fa4c0e80c.jpg</td>\n      <td>scab</td>\n    </tr>\n    <tr>\n      <th>18629</th>\n      <td>fffc94e092a59086.jpg</td>\n      <td>rust</td>\n    </tr>\n    <tr>\n      <th>18630</th>\n      <td>fffe105cf6808292.jpg</td>\n      <td>scab frog_eye_leaf_spot</td>\n    </tr>\n    <tr>\n      <th>18631</th>\n      <td>fffe472a0001bd25.jpg</td>\n      <td>healthy</td>\n    </tr>\n  </tbody>\n</table>\n<p>18632 rows × 2 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"dct = defaultdict(list)\n\nfor i, label in enumerate(data.labels):\n    for category in label.split():\n        dct[category].append(i)\n \ndct = {key: np.array(val) for key, val in dct.items()}\ndct","metadata":{"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"{'healthy': array([    0,     5,     7, ..., 18626, 18627, 18631]),\n 'scab': array([    1,     2,     3, ..., 18625, 18628, 18630]),\n 'frog_eye_leaf_spot': array([    1,    14,    31, ..., 18612, 18619, 18630]),\n 'complex': array([    1,     4,     8, ..., 18597, 18604, 18617]),\n 'rust': array([    6,    21,    26, ..., 18601, 18616, 18629]),\n 'powdery_mildew': array([   20,    39,    44, ..., 18532, 18617, 18618])}"},"metadata":{}}]},{"cell_type":"code","source":"new_df = pd.DataFrame(np.zeros((data.shape[0], len(dct.keys())), dtype=np.int8), columns=dct.keys())\n\nfor key, val in dct.items():\n    new_df.loc[val, key] = 1\n\nnew_df.head()","metadata":{"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"   healthy  scab  frog_eye_leaf_spot  complex  rust  powdery_mildew\n0        1     0                   0        0     0               0\n1        0     1                   1        1     0               0\n2        0     1                   0        0     0               0\n3        0     1                   0        0     0               0\n4        0     0                   0        1     0               0","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>healthy</th>\n      <th>scab</th>\n      <th>frog_eye_leaf_spot</th>\n      <th>complex</th>\n      <th>rust</th>\n      <th>powdery_mildew</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"data = pd.concat([data, new_df], axis=1)\ndata.to_csv('better_train.csv', index = False)\ndata","metadata":{"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"                      image                           labels  healthy  scab  \\\n0      800113bb65efe69e.jpg                          healthy        1     0   \n1      8002cb321f8bfcdf.jpg  scab frog_eye_leaf_spot complex        0     1   \n2      80070f7fb5e2ccaa.jpg                             scab        0     1   \n3      80077517781fb94f.jpg                             scab        0     1   \n4      800cbf0ff87721f8.jpg                          complex        0     0   \n...                     ...                              ...      ...   ...   \n18627  fffb900a92289a33.jpg                          healthy        1     0   \n18628  fffc488fa4c0e80c.jpg                             scab        0     1   \n18629  fffc94e092a59086.jpg                             rust        0     0   \n18630  fffe105cf6808292.jpg          scab frog_eye_leaf_spot        0     1   \n18631  fffe472a0001bd25.jpg                          healthy        1     0   \n\n       frog_eye_leaf_spot  complex  rust  powdery_mildew  \n0                       0        0     0               0  \n1                       1        1     0               0  \n2                       0        0     0               0  \n3                       0        0     0               0  \n4                       0        1     0               0  \n...                   ...      ...   ...             ...  \n18627                   0        0     0               0  \n18628                   0        0     0               0  \n18629                   0        0     1               0  \n18630                   1        0     0               0  \n18631                   0        0     0               0  \n\n[18632 rows x 8 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>image</th>\n      <th>labels</th>\n      <th>healthy</th>\n      <th>scab</th>\n      <th>frog_eye_leaf_spot</th>\n      <th>complex</th>\n      <th>rust</th>\n      <th>powdery_mildew</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>800113bb65efe69e.jpg</td>\n      <td>healthy</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>8002cb321f8bfcdf.jpg</td>\n      <td>scab frog_eye_leaf_spot complex</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>80070f7fb5e2ccaa.jpg</td>\n      <td>scab</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>80077517781fb94f.jpg</td>\n      <td>scab</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>800cbf0ff87721f8.jpg</td>\n      <td>complex</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>18627</th>\n      <td>fffb900a92289a33.jpg</td>\n      <td>healthy</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>18628</th>\n      <td>fffc488fa4c0e80c.jpg</td>\n      <td>scab</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>18629</th>\n      <td>fffc94e092a59086.jpg</td>\n      <td>rust</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>18630</th>\n      <td>fffe105cf6808292.jpg</td>\n      <td>scab frog_eye_leaf_spot</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>18631</th>\n      <td>fffe472a0001bd25.jpg</td>\n      <td>healthy</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>18632 rows × 8 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"train_data = data.sample(frac=0.8).reset_index(drop=True)\ntrain_data","metadata":{"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"                      image              labels  healthy  scab  \\\n0      ee4e84354b93d4c9.jpg                scab        0     1   \n1      a5c3aa145f345d4e.jpg  frog_eye_leaf_spot        0     0   \n2      ffd9a09d061e0e68.jpg                scab        0     1   \n3      809339deb2d6a50f.jpg                scab        0     1   \n4      961ff87d8c245ac2.jpg  frog_eye_leaf_spot        0     0   \n...                     ...                 ...      ...   ...   \n14901  e49a079f4479f1a4.jpg      powdery_mildew        0     0   \n14902  b1f045999924adbe.jpg                rust        0     0   \n14903  d5928febfc2cc090.jpg                scab        0     1   \n14904  f69c896b31b14d61.jpg                rust        0     0   \n14905  b740e716161e2d5d.jpg             healthy        1     0   \n\n       frog_eye_leaf_spot  complex  rust  powdery_mildew  \n0                       0        0     0               0  \n1                       1        0     0               0  \n2                       0        0     0               0  \n3                       0        0     0               0  \n4                       1        0     0               0  \n...                   ...      ...   ...             ...  \n14901                   0        0     0               1  \n14902                   0        0     1               0  \n14903                   0        0     0               0  \n14904                   0        0     1               0  \n14905                   0        0     0               0  \n\n[14906 rows x 8 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>image</th>\n      <th>labels</th>\n      <th>healthy</th>\n      <th>scab</th>\n      <th>frog_eye_leaf_spot</th>\n      <th>complex</th>\n      <th>rust</th>\n      <th>powdery_mildew</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>ee4e84354b93d4c9.jpg</td>\n      <td>scab</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>a5c3aa145f345d4e.jpg</td>\n      <td>frog_eye_leaf_spot</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>ffd9a09d061e0e68.jpg</td>\n      <td>scab</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>809339deb2d6a50f.jpg</td>\n      <td>scab</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>961ff87d8c245ac2.jpg</td>\n      <td>frog_eye_leaf_spot</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>14901</th>\n      <td>e49a079f4479f1a4.jpg</td>\n      <td>powdery_mildew</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>14902</th>\n      <td>b1f045999924adbe.jpg</td>\n      <td>rust</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>14903</th>\n      <td>d5928febfc2cc090.jpg</td>\n      <td>scab</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>14904</th>\n      <td>f69c896b31b14d61.jpg</td>\n      <td>rust</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>14905</th>\n      <td>b740e716161e2d5d.jpg</td>\n      <td>healthy</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>14906 rows × 8 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"test_data = pd.merge(data,train_data, indicator=True, how='outer').query('_merge==\"left_only\"').drop('_merge', axis=1).reset_index(drop=True)\ntest_data","metadata":{"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"                     image              labels  healthy  scab  \\\n0     80077517781fb94f.jpg                scab        0     1   \n1     801d6dcd96e48ebc.jpg             healthy        1     0   \n2     8021b94d437eb7d3.jpg             healthy        1     0   \n3     80230a9a3f7a9f6b.jpg                scab        0     1   \n4     80261f473eafb92c.jpg                scab        0     1   \n...                    ...                 ...      ...   ...   \n3721  fff00006af9e9c38.jpg  frog_eye_leaf_spot        0     0   \n3722  fff020893e070f27.jpg             healthy        1     0   \n3723  fff2e1c1e70300f0.jpg  frog_eye_leaf_spot        0     0   \n3724  fffb65761200b054.jpg             healthy        1     0   \n3725  fffc94e092a59086.jpg                rust        0     0   \n\n      frog_eye_leaf_spot  complex  rust  powdery_mildew  \n0                      0        0     0               0  \n1                      0        0     0               0  \n2                      0        0     0               0  \n3                      0        0     0               0  \n4                      0        0     0               0  \n...                  ...      ...   ...             ...  \n3721                   1        0     0               0  \n3722                   0        0     0               0  \n3723                   1        0     0               0  \n3724                   0        0     0               0  \n3725                   0        0     1               0  \n\n[3726 rows x 8 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>image</th>\n      <th>labels</th>\n      <th>healthy</th>\n      <th>scab</th>\n      <th>frog_eye_leaf_spot</th>\n      <th>complex</th>\n      <th>rust</th>\n      <th>powdery_mildew</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>80077517781fb94f.jpg</td>\n      <td>scab</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>801d6dcd96e48ebc.jpg</td>\n      <td>healthy</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>8021b94d437eb7d3.jpg</td>\n      <td>healthy</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>80230a9a3f7a9f6b.jpg</td>\n      <td>scab</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>80261f473eafb92c.jpg</td>\n      <td>scab</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>3721</th>\n      <td>fff00006af9e9c38.jpg</td>\n      <td>frog_eye_leaf_spot</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3722</th>\n      <td>fff020893e070f27.jpg</td>\n      <td>healthy</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3723</th>\n      <td>fff2e1c1e70300f0.jpg</td>\n      <td>frog_eye_leaf_spot</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3724</th>\n      <td>fffb65761200b054.jpg</td>\n      <td>healthy</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3725</th>\n      <td>fffc94e092a59086.jpg</td>\n      <td>rust</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>3726 rows × 8 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"### Creating NVIDIA DALI PipeLine","metadata":{}},{"cell_type":"code","source":"class ExternalInputIterator(object):\n    def __init__(self, batch_size, images_dir, data, device_id, num_gpus):\n        self.images_dir = images_dir\n        self.batch_size = batch_size\n        self.data = data\n        # whole data set size\n        self.data_set_len = len(self.data)\n        # based on the device_id and total number of GPUs - world size\n        # get proper shard\n        self.data = self.data[self.data_set_len * device_id // num_gpus:\n                                self.data_set_len * (device_id + 1) // num_gpus]\n        self.n = len(self.data)\n\n    def __iter__(self):\n        self.i = 0\n        self.data = self.data.sample(frac=1).reset_index(drop=True)\n        return self\n\n    def __next__(self):\n        batch = []\n        labels = []\n\n        if self.i >= self.n:\n            self.__iter__()\n            raise StopIteration\n\n        for _ in range(self.batch_size):\n            jpeg_filename, label = self.data.iloc[self.i % self.n].image, self.data.iloc[self.i % self.n][2:].to_numpy(dtype = np.uint8)\n            jpeg_filename = os.path.join(self.images_dir, jpeg_filename)\n            batch.append(torch.from_numpy(np.fromfile(jpeg_filename, dtype = np.uint8)))  # we can use numpy\n            labels.append(torch.from_numpy(label))\n            self.i += 1\n        return (batch, labels)\n\n    def __len__(self):\n        return self.data_set_len\n\n    next = __next__","metadata":{"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"def ExternalSourcePipelineTrain(batch_size, output_size, num_threads, device_id, external_data):\n    pipe = Pipeline(batch_size, num_threads, device_id)\n    with pipe:\n        jpegs, labels = fn.external_source(source=external_data, num_outputs=2)\n        images = fn.decoders.image(jpegs, device=\"mixed\")\n        images = fn.flip(images, horizontal = fn.random.coin_flip(), vertical = fn.random.coin_flip(), device = \"gpu\")\n        images = fn.rotate(images, angle=fn.random.uniform(range=(-90., 90.)), device = \"gpu\")\n        images = fn.random_resized_crop(images,\n                size = output_size,\n                random_area = [0.4, 1.0],\n                random_aspect_ratio = [0.5, 1.5],\n                device=\"gpu\",\n                )\n        images = fn.crop_mirror_normalize(\n                images,\n                dtype=types.FLOAT,\n                mean=[0.0, 0.0, 0.0],\n                std=[255., 255., 255.],\n                )\n        pipe.set_outputs(images, labels)\n    return pipe","metadata":{"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"def ExternalSourcePipelineTest(batch_size, output_size, num_threads, device_id, external_data):\n    pipe = Pipeline(batch_size, num_threads, device_id)\n    with pipe:\n        jpegs, labels = fn.external_source(source=external_data, num_outputs=2)\n        images = fn.decoders.image(jpegs, device=\"mixed\")\n        images = fn.resize(images, size=output_size)\n        images = fn.crop_mirror_normalize(\n                images,\n                dtype=types.FLOAT,\n                mean=[0.0, 0.0, 0.0],\n                std=[255., 255., 255.],\n                )\n        pipe.set_outputs(images, labels)\n    return pipe","metadata":{"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"### Checking PipeLine Validity","metadata":{}},{"cell_type":"code","source":"!mkdir Augmentation_Check","metadata":{"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"mkdir: cannot create directory ‘Augmentation_Check’: File exists\n","output_type":"stream"}]},{"cell_type":"code","source":"# eii = ExternalInputIterator(64, \"../input/plant-pathology-2021-fgvc8/train_images\", data, 0, 1)\n# pipe = ExternalSourcePipelineTrain(batch_size=64, output_size=(224,224), num_threads=2, device_id = 0,\n#                               external_data = eii)\n# pii = PyTorchIterator(pipe, last_batch_padded=True, last_batch_policy=LastBatchPolicy.PARTIAL)\n\n# count = 0\n# for e in range(1):\n#     for i, dt in enumerate(pii):\n#         image = dt[0]['data']\n#         if i < 10:\n#             grid = utils.make_grid(image)\n#             plt.imshow(grid.cpu().numpy().transpose((1, 2, 0)))\n#             plt.savefig(f\"./Augmentation_Check/{count}.png\", dpi=300)\n#             plt.close()\n#             count+=1\n#         sys.stdout.write(f\"\\r epoch: {e}, iter {i}, real batch size: {image.shape} and label {dt[0]['label'].shape}\")\n#     pii.reset()\n# print(\"\\nOK\")\n# torch.cuda.empty_cache()","metadata":{"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"### Model and Training Code","metadata":{}},{"cell_type":"code","source":"# Dictionary for pretrained models and their last layer name\npretrained_models = {\n    \"ResNet18\": [torchvision.models.resnet18, \"layer4\", (224, 224)],\n    \"ResNet34\": [torchvision.models.resnet34, \"layer4\", (224, 224)],\n    \"ResNet50\": [torchvision.models.resnet50, \"layer4\", (224, 224)],\n    \"ResNet101\": [torchvision.models.resnet101, \"layer4\", (224, 224)],\n    \"ResNet152\": [torchvision.models.resnet152, \"layer4\", (224, 224)],\n    \"Alexnet\": [torchvision.models.alexnet, \"features\", (256, 256)],\n    \"VGG11\": [torchvision.models.vgg11_bn, \"features\", (224, 224)],\n    \"VGG13\": [torchvision.models.vgg13_bn, \"features\", (224, 224)],\n    \"VGG16\": [torchvision.models.vgg16_bn, \"features\", (224, 224)],\n    \"VGG19\": [torchvision.models.vgg19_bn, \"features\", (224, 224)],\n    \"GoogleNet\": [torchvision.models.googlenet, \"inception5b\", (224, 224)],\n    \"Inception\": [torchvision.models.inception_v3, \"Mixed_7c\", (299, 299)],\n}","metadata":{"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"# The main model object\nclass PlantPathology:\n    \"\"\"\n    Model Architecture and Forward Training Path for the PlantPathology\n    Idea is to use transfer Learning\n    \"\"\"\n\n    def __init__(self, base_model=\"ResNet18\", colab=False):\n        assert base_model in [\n            \"ResNet18\",\n            \"ResNet34\",\n            \"ResNet50\",\n            \"ResNet101\",\n            \"ResNet152\",\n            \"Alexnet\",\n            \"VGG11\",\n            \"VGG13\",\n            \"VGG16\",\n            \"VGG19\",\n            \"GoogleNet\",\n            \"Inception\",\n        ]\n\n        # saving base model name to use it in saving the model\n        self.base_model = base_model\n        if colab:\n            self.colab_training = f\"drive/My Drive/{self.base_model}\"\n        else:\n            self.colab_training = \".\"\n\n        if not os.path.exists(f\"{self.colab_training}/model\"):\n            os.mkdir(f\"{self.colab_training}/model\")\n        if not os.path.exists(f\"{self.colab_training}/model_results\"):\n            os.mkdir(f\"{self.colab_training}/model_results\")\n\n        if os.path.exists(f\"{self.colab_training}/model/ConvModel_{self.base_model}\"):\n            # check if the model is intialized before\n            self.model = torch.load(\n                f\"{self.colab_training}/model/ConvModel_{self.base_model}\"\n            )\n        else:\n            # If not initialized before\n            # Download it and save it\n            self.model = pretrained_models[self.base_model][0](pretrained=True)\n            for name, param in self.model.named_parameters():\n                param.requires_grad = True\n\n            # Modify last Fully Connected layer to predict for\n            # Our requirements\n            if self.base_model in [\"Alexnet\", \"VGG11\", \"VGG13\", \"VGG16\", \"VGG19\"]:\n                num_ftrs = self.model.classifier[6].in_features\n                self.model.classifier[6] = torch.nn.Linear(num_ftrs, 6)\n            else:\n                self.model.fc = torch.nn.Sequential(\n                    torch.nn.Linear(self.model.fc.in_features, 500),\n                    torch.nn.ReLU(),\n                    torch.nn.Dropout(),\n                    torch.nn.Linear(500, 6),\n                )\n\n            # Save model\n            torch.save(\n                self.model, f\"{self.colab_training}/model/ConvModel_{self.base_model}\"\n            )\n\n        # get final model for using it in Class Activation Map\n        self.final_layer = self.model._modules.get(\n            pretrained_models[self.base_model][1]\n        )\n\n        # Different image transformations for training, testing and displaying\n        self.train_transformation = torchvision.transforms.Compose(\n            [\n                torchvision.transforms.RandomHorizontalFlip(),\n                torchvision.transforms.RandomVerticalFlip(),\n                torchvision.transforms.RandomRotation(90),\n                torchvision.transforms.RandomResizedCrop(\n                    pretrained_models[self.base_model][2],\n                    scale=(0.4, 1.0),\n                    ratio=(0.5, 1.5),\n                    interpolation=2,\n                ),\n                torchvision.transforms.ToTensor(),\n                torchvision.transforms.Normalize(\n                    mean=[0,0,0], std=[255,255,255]\n                ),\n            ]\n        )\n        self.test_transformation = torchvision.transforms.Compose(\n            [\n                torchvision.transforms.Resize(pretrained_models[self.base_model][2]),\n                torchvision.transforms.ToTensor(),\n                torchvision.transforms.Normalize(\n                    mean=[0,0,0], std=[255,255,255]\n                ),\n            ]\n        )\n        self.display_transformation = torchvision.transforms.Compose(\n            [\n                torchvision.transforms.Resize(pretrained_models[self.base_model][2]),\n            ]\n        )\n\n    def train(\n        self,\n        optimizer,\n        loss_fun,\n        train_data,\n        test_data,\n        epochs=20,\n        early_stopping_threshold=4,\n        device=\"cuda\",\n        dali = False\n    ):\n        \"\"\"\n        Train function:\n        parameters:\n        optimizer   : optimizer object\n        loss_fun    : Loss Function object\n        train_data  : train dataloader\n        test_data   : test  dataloader\n        epochs      : default value 20\n        early_stopping_threshold : Early stopping threshold\n        device      : 'cuda' or 'cpu', default 'cuda'\n        \"\"\"\n\n        # transfer model to device available\n        self.model.to(device)\n\n        max_accurracy = 0.0\n        train_losses = []\n        test_losses = []\n        train_accuracies = []\n        test_accuracies = []\n\n        for epoch in range(epochs):\n            start = time.time()\n\n            training_loss = 0.0\n\n            train_correct = 0\n            train_total = 0\n\n            # Training over batches\n            self.model.train(mode=True)\n            for i, train_batch in enumerate(train_data):\n                d = train_batch[0]\n                train_images, train_labels = d[\"data\"], d[\"label\"]\n                # train_images = train_images.permute(0,3,1,2)\n                train_images = train_images.to(device)\n                train_labels = train_labels.to(device, dtype=torch.float32).squeeze()\n\n                optimizer.zero_grad()\n                train_output = self.model(train_images)\n\n                if self.base_model == \"Inception\":\n                    train_output = train_output.logits\n#                 print(train_output.shape)\n#                 print(train_labels.shape)\n#                 print((torch.sigmoid(train_output) > 0.5).to(dtype=torch.float32))\n#                 print(train_labels)\n                train_loss = loss_fun(torch.sigmoid(train_output), train_labels)\n                \n                train_loss.backward()\n                optimizer.step()\n\n                training_loss += train_loss.item()\n                \n                train_predicted = (torch.sigmoid(train_output) > 0.5).to(dtype=torch.float32)\n                train_total += train_labels.shape[0] * train_labels.shape[1]\n                \n#                 print(\"Equal: \", (train_predicted == train_labels).sum().item())\n                \n                train_ccount = (train_predicted == train_labels).sum().item()\n                train_correct += train_ccount\n                \n                text = !nvidia-smi\n                text = text[9][60:65]\n                \n                sys.stdout.write(\n                    f\"\\rEpoch {epoch+1:03d}\\t\"\n                    f\"Train Loss => {train_loss:08.4f} \"\n                    f\"Train Accuracy => \"\n                    f\"{(train_ccount*100/(train_predicted.shape[0]*train_predicted.shape[1])):06.2f} \"\n                    f\"GPU Utilization => {text}\"\n                )\n        \n            train_data.reset()\n\n            training_accuracy = train_correct / train_total * 100\n\n            valid_loss = 0.0\n            test_correct = 0\n            test_total = 0\n            misses = 0\n            previous_accuracy = 0\n            tp = 0\n            fp = 0\n            fn = 0\n\n            # Test over batches\n            self.model.train(mode=False)\n            with torch.no_grad():\n                for i, test_batch in enumerate(test_data):    \n                    d = test_batch[0]\n                    test_images, test_labels = d[\"data\"], d[\"label\"]\n                    # test_images = test_images.permute(0,3,1,2)\n                    test_images = test_images.to(device)\n                    test_labels = test_labels.to(device, dtype=torch.float32).squeeze()\n\n                    test_output = self.model(test_images)\n\n                    test_loss = loss_fun(torch.sigmoid(test_output), test_labels)\n                    valid_loss += test_loss.item()\n\n                    test_predicted = (torch.sigmoid(test_output) > 0.5).to(dtype=torch.float32)\n\n                    test_total += test_labels.shape[0] * test_labels.shape[1]\n        \n                    test_ccount = (test_predicted == test_labels).sum().item()\n                    \n                    for i in range(test_labels.shape[0]):\n                        for j in range(test_labels.shape[1]):\n                            tp += int((test_labels[i][j] == 1) & ((test_predicted)[i][j] == 1))\n                            fn += int((test_labels[i][j] != 0) & ((test_predicted)[i][j] == 0))\n                            fp += int((test_labels[i][j] != 1) & ((test_predicted)[i][j] == 1))\n                    test_correct += test_ccount\n\n            testing_accuracy = test_correct / test_total * 100\n            testing_precision = tp / (tp + fp) * 100\n            testing_recall = tp / (tp + fn) * 100\n            testing_f1 = (\n                2.0\n                * testing_recall\n                * testing_precision\n                / (testing_recall + testing_precision)\n            )\n            test_data.reset()\n\n            sys.stdout.flush()\n            sys.stdout.write(\"\\r\")\n\n            time_taken = time.time() - start\n\n            print(\n                f\"Epoch {epoch + 1:03d}\\n\"\n                f\"Train Loss => {training_loss:08.4f} \"\n                f\"Train Accuracy => {training_accuracy:06.2f} \"\n                f\"Test Loss => {valid_loss:08.4f} \"\n                f\"Test Accuracy => {testing_accuracy:06.2f} \"\n                f\"Test Precision => {testing_precision:06.2f}\\n\"\n                f\"Test Recall => {testing_recall:06.2f} \"\n                f\"Test F1 Score => {testing_f1:06.2f} \"\n                f\"Time Taken => {time_taken:08.4f}\"\n                f\"\\n{'='*100}\"\n            )\n\n            train_losses.append(training_loss)\n            test_losses.append(valid_loss)\n            train_accuracies.append(training_accuracy)\n            test_accuracies.append(testing_accuracy)\n\n            # Save if it is better model than max_accuracy\n            if testing_accuracy > max_accurracy:\n                max_accurracy = testing_accuracy\n                torch.save(\n                    self.model,\n                    f\"{self.colab_training}/model/ConvModel_{self.base_model}\",\n                )\n\n                with open(\n                    f\"{self.colab_training}/model_results/ConvModel_{self.base_model}_results.txt\",\n                    \"w\",\n                ) as f:\n                    f.writelines(\n                        [\n                            f\"BaseModel: {self.base_model}\\n\",\n                            f\"Epochs: {epoch + 1:03d}\\n\",\n                            f\"Train Dataloader Batch Size: {train_data.batch_size}\\n\",\n                            f\"Test Dataloader Batch Size: {test_data.batch_size}\\n\",\n                            f\"Params for Optimizer: {optimizer.__repr__()}\\n\",\n                            f\"Train Loss: {training_loss:08.4f}\\n\",\n                            f\"Test Loss: {valid_loss:08.4f}\\n\",\n                            f\"Train Accuracy: {training_accuracy:06.2f}\\n\",\n                            f\"Test Accuracy: {testing_accuracy:06.2f}\\n\",\n                            f\"Test Precision: {testing_precision:06.2f}\\n\",\n                            f\"Test Recall: {testing_recall:06.2f}\\n\",\n                            f\"Test F1 Score: {testing_f1:06.2f}\\n\",\n                            f\"Time Taken: {time_taken:08.4f} seconds\",\n                        ]\n                    )\n\n            # Decide and stop early if needed\n            if epoch >= 1:\n                if (\n                    previous_accuracy > testing_accuracy\n                    and misses < early_stopping_threshold\n                ):\n                    misses += 1\n                    previous_accuracy = testing_accuracy\n                elif previous_accuracy > testing_accuracy:\n                    print(f\"Early Stopping....\")\n                    print(\n                        f\"Epoch {epoch + 1:03d}\\t\"\n                        f\"Train Loss => {training_loss:08.4f} \"\n                        f\"Train accuracy => {training_accuracy:06.2f} \"\n                        f\"Test Loss => {valid_loss:08.4f} \"\n                        f\"Test Accuracy => {testing_accuracy:06.2f} \"\n                        f\"Test Precision => {testing_precision:06.2f} \"\n                        f\"Test Recall => {testing_recall:06.2f} \"\n                        f\"Test F1 Score => {testing_f1:06.2f} \"\n                        f\"Time Taken => {time_taken:08.4f}\"\n                    )\n                    break\n            previous_accuracy = testing_accuracy\n\n            np.save(\n                f\"{self.colab_training}/model/train_losses_{self.base_model}\",\n                train_losses,\n            )\n            np.save(\n                f\"{self.colab_training}/model/train_accuracies_{self.base_model}\",\n                train_accuracies,\n            )\n            np.save(\n                f\"{self.colab_training}/model/test_losses_{self.base_model}\",\n                test_losses,\n            )\n            np.save(\n                f\"{self.colab_training}/model/test_accuracies_{self.base_model}\",\n                test_accuracies,\n            )\n\n    def test(self, loss_fun, test_data, device=\"cuda\", has_labels=False, dali=False):\n        print(\"Starting Evaluating....\")\n        start = time.time()\n        valid_loss = 0.0\n        test_correct = 0\n        test_total = 0\n        misses = 0\n        previous_accuracy = 0\n        tp = 0\n        fp = 0\n        fn = 0\n\n        # Test over batches\n        self.model.train(mode=False)\n        with torch.no_grad():\n            for i, test_batch in enumerate(test_data):    \n                d = test_batch[0]\n                test_images, test_labels = d[\"data\"], d[\"label\"]\n                # test_images = test_images.permute(0,3,1,2)\n                test_images = test_images.to(device)\n                test_labels = test_labels.to(device, dtype=torch.float32).squeeze()\n\n                test_output = self.model(test_images)\n\n                test_loss = loss_fun(torch.sigmoid(test_output), test_labels)\n                valid_loss += test_loss.item()\n\n                test_predicted = (torch.sigmoid(test_output) > 0.5).to(dtype=torch.float32)\n\n                test_total += test_labels.shape[0] * test_label.shape[1]\n\n                test_ccount = (test_predicted == test_labels).sum().item()\n\n                for i in test_labels.shape[0]:\n                    for j in test_labels.shape[1]:\n                        tp += int((test_labels[i][j] == 1) & ((test_predicted)[i][j] == 1))\n                        fn += int((test_labels[i][j] != 0) & ((test_predicted)[i][j] == 0))\n                        fp += int((test_labels[i][j] != 1) & ((test_predicted)[i][j] == 1))\n                test_correct += test_ccount\n\n        testing_accuracy = test_correct / test_total * 100\n        testing_precision = tp / (tp + fp) * 100\n        testing_recall = tp / (tp + fn) * 100\n        testing_f1 = (\n            2.0\n            * testing_recall\n            * testing_precision\n            / (testing_recall + testing_precision)\n        )\n        test_data.reset()\n\n        sys.stdout.flush()\n        sys.stdout.write(\"\\r\")\n\n    def CAM(self, image_path_input, overlay_path_output, device=\"cuda\"):\n        \"\"\"\n        CAM - Class Activation Map\n        \"\"\"\n\n        # open image\n        image = Image.open(image_path_input)\n        image = image.convert(\"RGB\")\n        print(image.mode)\n\n        tensor = self.test_transformation(image)\n\n        prediction_var = torch.autograd.Variable(\n            (tensor.unsqueeze(0)).cuda(), requires_grad=True\n        )\n        self.model.to(device)\n        self.model.eval()\n\n        class SaveFeatures:\n            features = None\n\n            def __init__(self, m):\n                self.hook = m.register_forward_hook(self.hook_fn)\n\n            def hook_fn(self, module, input, output):\n                self.features = ((output.cpu()).data).numpy()\n\n            def remove(self):\n                self.hook.remove()\n\n        activated_features = SaveFeatures(self.final_layer)\n        prediction_var = prediction_var.to(device)\n        prediction = self.model(prediction_var)\n\n        pred_probabilities = torch.nn.functional.softmax(\n            prediction, dim=0\n        ).data.squeeze()\n\n        activated_features.remove()\n\n        torch.topk(pred_probabilities, 1)\n\n        def getCAM(feature_conv, weight_fc, class_idx):\n            _, nc, h, w = feature_conv.shape\n            cam = weight_fc[class_idx].dot(feature_conv.reshape((nc, h * w)))\n            cam = cam.reshape(h, w)\n            cam = cam - np.min(cam)\n            cam_img = cam / np.max(cam)\n            return [cam_img]\n\n        weight_softmax_params = list(self.model._modules.get(\"fc\").parameters())\n        weight_softmax = np.squeeze(weight_softmax_params[0].cpu().data.numpy())\n\n        class_idx = torch.topk(pred_probabilities, 1)[1].int()\n\n        overlay = getCAM(activated_features.features, weight_softmax, class_idx)\n\n        plt.figure(figsize=(32, 15))\n        plt.subplot(1, 2, 1)\n        plt.imshow(self.display_transformation(image))\n        plt.subplot(1, 2, 2)\n        plt.imshow(self.display_transformation(image))\n        plt.imshow(\n            skimage.transform.resize(overlay[0], tensor.shape[1:3]),\n            alpha=0.4,\n            cmap=\"jet\",\n        )\n        plt.savefig(overlay_path_output)","metadata":{"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"if torch.cuda.is_available():\n    print(\"Using GPU\")\n    device = torch.device(\"cuda\")\nelse:\n    print(\"Using CPU\")\n    device = torch.device(\"cpu\")","metadata":{"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"Using GPU\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Hyperparameters","metadata":{}},{"cell_type":"code","source":"batch_size = 32\nlearning_rate = 0.0001\ndali = True\nN_GPUS = 1\nepochs = 10\nbase_model = \"ResNet50\"\noptimizer_name = 'Adam'\ncolab = False\nimage_dir = \"../input/plant-pathology-2021-fgvc8/train_images\"","metadata":{"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"print(\"Creating Model Object: \")\nmodel = PlantPathology(base_model, colab=colab)","metadata":{"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"Creating Model Object: \n","output_type":"stream"}]},{"cell_type":"markdown","source":"### DataLoader","metadata":{}},{"cell_type":"code","source":"train_eii = ExternalInputIterator(batch_size, image_dir, train_data, 0, 1)\npipe_train = ExternalSourcePipelineTrain(batch_size=batch_size, output_size=pretrained_models[base_model][2], num_threads=2, device_id = 0,\n                              external_data = train_eii)\ntrain_data_loader = PyTorchIterator(pipe_train, last_batch_padded=True, last_batch_policy=LastBatchPolicy.PARTIAL)\n\ntest_eii = ExternalInputIterator(batch_size, image_dir, test_data, 0, 1)\npipe_test = ExternalSourcePipelineTest(batch_size=batch_size, output_size=pretrained_models[base_model][2], num_threads=2, device_id = 0,\n                              external_data = test_eii)\ntest_data_loader = PyTorchIterator(pipe_test, last_batch_padded=True, last_batch_policy=LastBatchPolicy.PARTIAL)","metadata":{"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"markdown","source":"### Optimizer and Training","metadata":{}},{"cell_type":"code","source":"optimizers = {\n    \"Adam\": torch.optim.Adam,\n    \"SGD\": torch.optim.SGD,\n    \"RMSprop\": torch.optim.RMSprop,\n    \"Adagrad\": torch.optim.Adagrad,\n    \"Adadelta\": torch.optim.Adadelta,\n}","metadata":{"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"optimizer = optimizers[optimizer_name](\n    model.model.parameters(), lr=learning_rate\n)\n\nprint(\"Starting Training\")    \nmodel.train(\n    optimizer,\n    torch.nn.BCELoss(),\n    train_data_loader,\n    test_data_loader,\n    epochs=epochs,\n    device=device,\n    dali=dali\n)\nprint(\"Completed Training\")","metadata":{"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"Starting Training\nEpoch 001\tTrain Loss => 000.0696 Train Accuracy => 097.40 GPU Utilization =>  45% \nTrain Loss => 060.1852 Train Accuracy => 095.04 Test Loss => 012.1428 Test Accuracy => 095.84 Test Precision => 091.28\nTest Recall => 085.24 Test F1 Score => 088.16 Time Taken => 483.1266\n======================================================================================================================================================\nEpoch 002\tTrain Loss => 000.0764 Train Accuracy => 096.35 GPU Utilization =>  58% \nTrain Loss => 055.1978 Train Accuracy => 095.38 Test Loss => 012.3646 Test Accuracy => 095.81 Test Precision => 090.40\nTest Recall => 086.08 Test F1 Score => 088.18 Time Taken => 505.4285\n======================================================================================================================================================\nEpoch 003\tTrain Loss => 000.1588 Train Accuracy => 093.23 GPU Utilization =>  77% \nTrain Loss => 050.5900 Train Accuracy => 095.76 Test Loss => 010.9844 Test Accuracy => 096.27 Test Precision => 091.18\nTest Recall => 087.96 Test F1 Score => 089.54 Time Taken => 509.2396\n======================================================================================================================================================\nEpoch 004\tTrain Loss => 000.1879 Train Accuracy => 094.27 GPU Utilization =>  68% \nTrain Loss => 047.7581 Train Accuracy => 096.01 Test Loss => 011.1908 Test Accuracy => 096.33 Test Precision => 092.22\nTest Recall => 087.15 Test F1 Score => 089.61 Time Taken => 516.2807\n======================================================================================================================================================\nEpoch 005\tTrain Loss => 000.0917 Train Accuracy => 095.83 GPU Utilization =>  84% \nTrain Loss => 045.6451 Train Accuracy => 096.12 Test Loss => 011.6872 Test Accuracy => 096.01 Test Precision => 089.55\nTest Recall => 088.32 Test F1 Score => 088.94 Time Taken => 506.5680\n======================================================================================================================================================\nEpoch 006\tTrain Loss => 000.0622 Train Accuracy => 097.40 GPU Utilization =>  94% \nTrain Loss => 043.9826 Train Accuracy => 096.23 Test Loss => 010.9775 Test Accuracy => 096.34 Test Precision => 091.02\nTest Recall => 088.55 Test F1 Score => 089.77 Time Taken => 507.2330\n======================================================================================================================================================\nEpoch 007\tTrain Loss => 000.0815 Train Accuracy => 095.83 GPU Utilization =>  53% \nTrain Loss => 042.6892 Train Accuracy => 096.34 Test Loss => 010.4608 Test Accuracy => 096.41 Test Precision => 090.45\nTest Recall => 089.70 Test F1 Score => 090.07 Time Taken => 517.5914\n======================================================================================================================================================\nEpoch 008\tTrain Loss => 000.0365 Train Accuracy => 098.96 GPU Utilization =>  50% \nTrain Loss => 042.3882 Train Accuracy => 096.40 Test Loss => 010.8111 Test Accuracy => 096.50 Test Precision => 090.40\nTest Recall => 090.29 Test F1 Score => 090.34 Time Taken => 508.1564\n======================================================================================================================================================\nEpoch 009\tTrain Loss => 000.0818 Train Accuracy => 096.35 GPU Utilization =>  49% \nTrain Loss => 041.4023 Train Accuracy => 096.49 Test Loss => 010.7493 Test Accuracy => 096.24 Test Precision => 089.84\nTest Recall => 089.40 Test F1 Score => 089.62 Time Taken => 513.7929\n======================================================================================================================================================\nEpoch 010\tTrain Loss => 000.0889 Train Accuracy => 095.83 GPU Utilization =>  78% \nTrain Loss => 039.6087 Train Accuracy => 096.57 Test Loss => 009.8693 Test Accuracy => 096.59 Test Precision => 091.44\nTest Recall => 089.58 Test F1 Score => 090.50 Time Taken => 513.1842\n======================================================================================================================================================\nCompleted Training\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}